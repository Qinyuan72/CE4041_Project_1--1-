2024-11-06 19:31:30.834663: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error
2024-11-06 19:31:30.834682: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: emstudy
2024-11-06 19:31:30.834685: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: emstudy
2024-11-06 19:31:30.834791: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 560.35.3
2024-11-06 19:31:30.834803: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 560.35.3
2024-11-06 19:31:30.834805: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 560.35.3
Epoch 1/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m19s[0m 12ms/step - accuracy: 0.6958 - loss: 0.9449 - precision: 0.8867 - recall: 0.5325 - val_accuracy: 0.9577 - val_loss: 0.1461 - val_precision: 0.9691 - val_recall: 0.9486
Epoch 2/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m17s[0m 11ms/step - accuracy: 0.9414 - loss: 0.1889 - precision: 0.9540 - recall: 0.9285 - val_accuracy: 0.9731 - val_loss: 0.0912 - val_precision: 0.9784 - val_recall: 0.9684
Epoch 3/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9602 - loss: 0.1261 - precision: 0.9681 - recall: 0.9530 - val_accuracy: 0.9785 - val_loss: 0.0725 - val_precision: 0.9820 - val_recall: 0.9755
Epoch 4/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m14s[0m 9ms/step - accuracy: 0.9698 - loss: 0.0951 - precision: 0.9747 - recall: 0.9649 - val_accuracy: 0.9815 - val_loss: 0.0591 - val_precision: 0.9847 - val_recall: 0.9799
Epoch 5/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9751 - loss: 0.0776 - precision: 0.9787 - recall: 0.9723 - val_accuracy: 0.9841 - val_loss: 0.0525 - val_precision: 0.9861 - val_recall: 0.9818
Epoch 6/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9786 - loss: 0.0674 - precision: 0.9819 - recall: 0.9751 - val_accuracy: 0.9850 - val_loss: 0.0483 - val_precision: 0.9870 - val_recall: 0.9830
Epoch 7/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m14s[0m 9ms/step - accuracy: 0.9806 - loss: 0.0593 - precision: 0.9835 - recall: 0.9784 - val_accuracy: 0.9861 - val_loss: 0.0452 - val_precision: 0.9883 - val_recall: 0.9847
Epoch 8/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9835 - loss: 0.0533 - precision: 0.9858 - recall: 0.9810 - val_accuracy: 0.9871 - val_loss: 0.0415 - val_precision: 0.9889 - val_recall: 0.9858
Epoch 9/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m18s[0m 12ms/step - accuracy: 0.9835 - loss: 0.0507 - precision: 0.9855 - recall: 0.9818 - val_accuracy: 0.9877 - val_loss: 0.0408 - val_precision: 0.9890 - val_recall: 0.9870
Epoch 10/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 11ms/step - accuracy: 0.9858 - loss: 0.0459 - precision: 0.9874 - recall: 0.9840 - val_accuracy: 0.9874 - val_loss: 0.0398 - val_precision: 0.9886 - val_recall: 0.9864
Epoch 11/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 11ms/step - accuracy: 0.9864 - loss: 0.0417 - precision: 0.9880 - recall: 0.9854 - val_accuracy: 0.9893 - val_loss: 0.0365 - val_precision: 0.9908 - val_recall: 0.9882
Epoch 12/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 11ms/step - accuracy: 0.9880 - loss: 0.0385 - precision: 0.9896 - recall: 0.9867 - val_accuracy: 0.9891 - val_loss: 0.0360 - val_precision: 0.9898 - val_recall: 0.9880
Epoch 13/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 11ms/step - accuracy: 0.9891 - loss: 0.0356 - precision: 0.9904 - recall: 0.9880 - val_accuracy: 0.9897 - val_loss: 0.0341 - val_precision: 0.9907 - val_recall: 0.9892
Epoch 14/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9893 - loss: 0.0335 - precision: 0.9909 - recall: 0.9884 - val_accuracy: 0.9903 - val_loss: 0.0335 - val_precision: 0.9915 - val_recall: 0.9893
Epoch 15/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9897 - loss: 0.0307 - precision: 0.9911 - recall: 0.9887 - val_accuracy: 0.9896 - val_loss: 0.0340 - val_precision: 0.9907 - val_recall: 0.9888
Epoch 16/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 10ms/step - accuracy: 0.9894 - loss: 0.0304 - precision: 0.9907 - recall: 0.9888 - val_accuracy: 0.9904 - val_loss: 0.0322 - val_precision: 0.9914 - val_recall: 0.9898
Epoch 17/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m14s[0m 10ms/step - accuracy: 0.9908 - loss: 0.0275 - precision: 0.9920 - recall: 0.9896 - val_accuracy: 0.9902 - val_loss: 0.0321 - val_precision: 0.9912 - val_recall: 0.9897
Epoch 18/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9923 - loss: 0.0254 - precision: 0.9929 - recall: 0.9917 - val_accuracy: 0.9907 - val_loss: 0.0314 - val_precision: 0.9914 - val_recall: 0.9900
Epoch 19/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9920 - loss: 0.0253 - precision: 0.9927 - recall: 0.9914 - val_accuracy: 0.9907 - val_loss: 0.0325 - val_precision: 0.9912 - val_recall: 0.9902
Epoch 20/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9920 - loss: 0.0237 - precision: 0.9929 - recall: 0.9916 - val_accuracy: 0.9911 - val_loss: 0.0316 - val_precision: 0.9920 - val_recall: 0.9907
Epoch 21/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 10ms/step - accuracy: 0.9935 - loss: 0.0201 - precision: 0.9942 - recall: 0.9931 - val_accuracy: 0.9908 - val_loss: 0.0311 - val_precision: 0.9915 - val_recall: 0.9903
Epoch 22/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9932 - loss: 0.0211 - precision: 0.9940 - recall: 0.9926 - val_accuracy: 0.9909 - val_loss: 0.0307 - val_precision: 0.9919 - val_recall: 0.9898
Epoch 23/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m14s[0m 10ms/step - accuracy: 0.9943 - loss: 0.0188 - precision: 0.9947 - recall: 0.9939 - val_accuracy: 0.9908 - val_loss: 0.0307 - val_precision: 0.9916 - val_recall: 0.9904
Epoch 24/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9942 - loss: 0.0181 - precision: 0.9947 - recall: 0.9938 - val_accuracy: 0.9904 - val_loss: 0.0313 - val_precision: 0.9913 - val_recall: 0.9901
Epoch 25/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9945 - loss: 0.0173 - precision: 0.9950 - recall: 0.9942 - val_accuracy: 0.9912 - val_loss: 0.0309 - val_precision: 0.9918 - val_recall: 0.9909
Epoch 26/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9950 - loss: 0.0170 - precision: 0.9953 - recall: 0.9947 - val_accuracy: 0.9912 - val_loss: 0.0316 - val_precision: 0.9920 - val_recall: 0.9909
Epoch 27/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m15s[0m 10ms/step - accuracy: 0.9943 - loss: 0.0178 - precision: 0.9945 - recall: 0.9940 - val_accuracy: 0.9912 - val_loss: 0.0332 - val_precision: 0.9917 - val_recall: 0.9906
Epoch 28/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 10ms/step - accuracy: 0.9956 - loss: 0.0162 - precision: 0.9958 - recall: 0.9951 - val_accuracy: 0.9909 - val_loss: 0.0308 - val_precision: 0.9915 - val_recall: 0.9908
Epoch 29/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 11ms/step - accuracy: 0.9944 - loss: 0.0163 - precision: 0.9948 - recall: 0.9941 - val_accuracy: 0.9898 - val_loss: 0.0339 - val_precision: 0.9907 - val_recall: 0.9893
Epoch 30/30
[1m1500/1500[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 10ms/step - accuracy: 0.9953 - loss: 0.0147 - precision: 0.9957 - recall: 0.9950 - val_accuracy: 0.9912 - val_loss: 0.0314 - val_precision: 0.9918 - val_recall: 0.9908
[1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step
[1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 3ms/step - accuracy: 0.9900 - loss: 0.0290 - precision: 0.9907 - recall: 0.9895
Model3 - Description: Structure based on Lecture notes detail
#Epochs: 30, Dropout Rate: 0.2, Batch Size: 32, Validation Split: 0.2, Learning Rate: 0.0001, Kernel Size: 5, Filter Size: 15, Regularizer: 1e-06, Seed: 42, ACCURACY: 0.9925000071525574, Loss: 0.02341356873512268, Precision: 0.9930930733680725, Recall: 0.9921000003814697, Experiment #1


 Total params: 591,050 (2.25 MB)
 Trainable params: 197,016 (769.59 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 394,034 (1.50 MB)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d (Conv2D)                 â”‚ (None, 28, 28, 15)     â”‚           390 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 14, 14, 15)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)               â”‚ (None, 14, 14, 15)     â”‚         5,640 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 7, 7, 15)       â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)               â”‚ (None, 735)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (None, 735)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 256)            â”‚       188,416 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)             â”‚ (None, 256)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 10)             â”‚         2,570 â”‚

Confusion Matrix
[[ 974    0    1    0    0    0    3    1    1    0]
 [   0 1132    1    1    0    0    1    0    0    0]
 [   1    1 1025    1    0    0    0    4    0    0]
 [   0    0    2 1005    0    3    0    0    0    0]
 [   0    0    0    0  978    0    1    0    0    3]
 [   1    0    0    6    0  883    2    0    0    0]
 [   2    2    0    0    1    1  952    0    0    0]
 [   0    2    2    3    0    0    0 1019    0    2]
 [   2    0    3    1    0    1    2    2  960    3]
 [   0    0    0    2    6    2    0    2    0  997]]


