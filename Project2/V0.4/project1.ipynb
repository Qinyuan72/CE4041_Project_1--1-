{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBlGUlanfAnm"
   },
   "source": [
    "# Version  \n",
    "** 1.2 **  \n",
    "1.2 Support for EXPLORE_MODE, allowing for succinct or full logging of data  \n",
    "1.1 Added plot support  \n",
    "1.0 1st release after review.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This is just an increasing number. If you make a change increase the number - major.minor  \n",
    "\n",
    "\n",
    "Develop a program in Python using the Keras Neural Network to implement a classifier fot the NMIST handwritten digits database. It is recommended to use a convolution neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Team  \n",
    "Qinyuan                 20137095  \n",
    "Eamon Moloney           8457077  \n",
    "Ibrahim Saana Aminu     25381993  \n",
    "Des Powell              9513833  \n",
    "Terence Coffey          15223124  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBoost\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_library\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcpl\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Main program\n",
    "#\n",
    "# 27/11/24\n",
    "# Ver 0.4   Initial version for testing\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# library imports\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common.algorithm import AdaBoost\n",
    "import common.plot_library as cpl\n",
    "from implementations.sklearn_weak_classifier import SklearnWeakClassifier\n",
    "from implementations.custom_weak_classifier import CustomWeakClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# constants\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "ITERATIONS = 50\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load data into numpy arrays\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "train_file = './adaboost-train-24.txt'\n",
    "test_file = './adaboost-test-24.txt'\n",
    "column_names = ['X1', 'X2', 'Y']\n",
    "df_train = pd.read_csv(train_file, sep=r'\\s+', header=None, names=column_names)\n",
    "df_test = pd.read_csv(test_file, sep=r'\\s+', header=None, names=column_names)\n",
    "X_train = df_train[['X1', 'X2']].to_numpy()\n",
    "Y_train = df_train['Y'].to_numpy()\n",
    "X_test = df_test[['X1', 'X2']].to_numpy()\n",
    "Y_test = df_test['Y'].to_numpy()\n",
    "#print(df_test.describe())\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "# Main \n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "\n",
    "    # 1 - TEST ACCURACY AFTER N ITERATIONS - Ntest = 26\n",
    "    Ntest=26\n",
    "    weak_classifier_ = CustomWeakClassifier() # simlply replace CustomWeakClassifier() with SklearnWeakClassifier() if using sklearn implementation\n",
    "    adaboost_strong_classifier_ = AdaBoost(weak_classifier_strategy=weak_classifier_)    \n",
    "    classifiers_, alphas_ = adaboost_strong_classifier_.train(X_train, Y_train, Ntest)\n",
    "    y_test_pred, y_test_pred_value = adaboost_strong_classifier_.predict(X_test, classifiers_[:Ntest], alphas_[:Ntest])\n",
    "    accuracy = accuracy_score(Y_test, y_test_pred)\n",
    "    print(f\"Step 1 - Strong Classifier Test Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    \n",
    "    # 2 - MEASURE TRAIN & TEST ACCURACY OVER Ntest plus ITERATIONS \n",
    "    cpl.train_acc, cpl.test_acc = measure_accuracy_of_predictions(adaboost_strong_classifier_, classifiers_, alphas_, ITERATIONS)\n",
    "    print(f\"Step 2 - Accuracy: Train {cpl.train_acc[-1]:.2%}, Test {cpl.test_acc[-1]:.2%}\")\n",
    "    \n",
    "    # 3 - GENERATE DECISION BOUNDRY DATA - using training data\n",
    "    print(f\"Step 3 - Generate Decision Boundry Data\")\n",
    "    cpl.X, cpl.y, cpl.Z, cpl.xx, cpl.yy = generate_decision_boundry_data(X_train, Y_train, adaboost_strong_classifier_, classifiers_, alphas_, Ntest)\n",
    "    \n",
    "    # 4 - GENERATE CONTOUR DATA - using test data\n",
    "    print(f\"Step 4 - Generate Contour Data\")\n",
    "    cpl.Z_values, cpl.xx, cpl.yy = generate_contour_data(X_train, adaboost_strong_classifier_, classifiers_, alphas_, Ntest)\n",
    "       \n",
    "    # 5. PLOTS \n",
    "    print(f\"Step 5 - Plots\")\n",
    "    cpl.generate_plots()\n",
    " \n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "# measure_accuracy_of_predictions \n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "def measure_accuracy_of_predictions(adaboost_classifier, classifiers, alphas, iterations):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for t in range(1, iterations + 1):\n",
    "        y_train_pred, not_used = adaboost_classifier.predict(X_train, classifiers[:t], alphas[:t])\n",
    "        y_test_pred, not_used = adaboost_classifier.predict(X_test, classifiers[:t], alphas[:t])\n",
    "        train_acc.append(accuracy_score(Y_train, y_train_pred))\n",
    "        test_acc.append(accuracy_score(Y_test, y_test_pred))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "# generate_decision_boundry_data \n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "def generate_decision_boundry_data(X, y, adaboost_classifier, classifiers, alphas, N_value):\n",
    "    resolution=0.01\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    # create a mesh grid covering the feature space\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                         np.arange(y_min, y_max, resolution))   \n",
    "    # predict class probabilities for each point in the mesh grid\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z, Z_values = zip(*[\n",
    "            adaboost_classifier.predict(point.reshape(1, -1), classifiers[:N_value], alphas[:N_value])\n",
    "            for point in grid_points\n",
    "        ])\n",
    "    Z = np.array(Z).reshape(xx.shape)  \n",
    "\n",
    "    return X, y, Z, xx, yy\n",
    "    \n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "# generate_contour_data \n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "def generate_contour_data(X, adaboost_classifier, classifiers, alphas, N_value):\n",
    "    resolution=0.01\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    #xx, yy = np.mgrid[x_min:x_max:0.01, y_min:y_max:0.01] \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                        np.arange(y_min, y_max, resolution))  \n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()] \n",
    "    Z, Z_values = zip(*[\n",
    "            adaboost_classifier.predict(point.reshape(1, -1), classifiers[:N_value], alphas[:N_value])\n",
    "            for point in grid_points\n",
    "        ])\n",
    "    Z_values = np.array(Z_values).reshape(xx.shape)\n",
    "    return Z_values, xx, yy\n",
    "    \n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make main run first\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRNNFokbIXa4"
   },
   "source": [
    "Application using Keras for MNIST Digit Classifier using 2 convolution layers , 2 drop out layers and 2 accumulation layers. Split the dataset into training and test data in the ratio 70 percent and 30 percent respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPxvrZuYrdCC"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqiWApzUI8hk"
   },
   "source": [
    "Display accuracy of Testing and Validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXcGog1PJNbA"
   },
   "source": [
    "Discuss the Project especially\n",
    "- How you choose to tackle it\n",
    "- What design decisions you made\n",
    "- What the results are like\n",
    "- What you might do better/differently next time you had to tackle a similar project\n",
    "- If plots are called for they should be in your code and in your report.\n",
    "- Marks for neat well designed code with appropriate level of comments\n",
    "- neat logically laid out and informative reports.\n",
    "- Provide classification accuracy for the training and test data. The test data should be split in the ration 70 to 80 and the baance for validation.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
